---
title: "p8105_hw2_jw4348"
author: "Jingyu Wang"
output: github_document
date: "2023-10-04"
---

```{r, echo = FALSE, message = FALSE}
  library(tidyverse)
  library(readxl)
```

## Problem 1: 

- First, we clean the data in `pols-month.csv.`.

```{r}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
    )
```

```{r}
pols = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

- Then, we clean the data in `snp.csv`.

```{r clean_538_snp}
snp = 
  read_csv(
    "./data/fivethirtyeight_datasets/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
```

- Finally, we tidy the `unemployment` data so that it can be merged with the `pols` and `snp` datasets.

```{r clean_538_unemp}
unemployment = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

- Now we merge the three datasets!

```{r merge_538}
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```

- Let's talk about the 538 datasets. The `pols` data has `r nrow(pols)` observations and `r ncol(pols)` variables and tells us about the party affiliation distribution (democrat or republican) for governors and senators for a given year from years `r pols |> pull(year) |> min()` to `r pols |> pull(year) |> max()`. It also tells us whether the sitting president was a democrat or republican. The `snp` data has `r nrow(snp)` observations and `r ncol(snp)` variables, ranging from years `r snp |> pull(year) |> min()` to `r snp |> pull(year) |> max()`. The `unemployment` data has `r nrow(unemployment)` observations and `r ncol(unemployment)` variables ranging from years `r unemployment |> pull(year) |> min()` to `r unemployment |> pull(year) |> max()`. In Januarys in or after 1975 in which a democrat was president, the **average unemployment rate was `r filter(data_538, month == "January", year >= 1975, president == "dem") |> pull(unemployment) |> mean() |> round(2)`**.  The average unemployment rate over the same time period in which a republican was president was `r filter(data_538, month == "January", year >= 1975, president == "gop") |> pull(unemployment) |> mean() |> round(2)`.

## Problem 2: 

- First we read and clean the `Mr. Trash Wheel sheet`.

```{r}
MrTrashWheel_df = 
  readxl::read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N586") |> 
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(
    homes_powered = (weight_tons * 500) / 30,
    type = "Mr Trash Wheel",
    year = as.double(year)
  )
 
MrTrashWheel_df
```

- Next we read and clean the `Professor Trash Wheel`.

```{r}
ProfessorTrashWheel_df = 
  readxl::read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M108") |> 
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(
    homes_powered = (weight_tons * 500) / 30,
    type = "Professor Trash Wheel"
    )

ProfessorTrashWheel_df
```

- Then we read and clean the `Gwynnda Trash Wheel`.

```{r}
GwynndaTrashWheel_df = 
  readxl::read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet =   "Gwynnda Trash Wheel", range = "A2:L157") |> 
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(
    homes_powered = (weight_tons * 500) / 30,
    type = "Gwynnda Trash Wheel"
  )

GwynndaTrashWheel_df
```

- Now we merge the three datasets, and proce a single tidy dataset named `Trashtidy_df`.

```{r}
Trashtidy_df = 
  bind_rows(MrTrashWheel_df, ProfessorTrashWheel_df, GwynndaTrashWheel_df) |>
  janitor::clean_names() 

Trashtidy_df
```

- Blow is the description of dataset `Trashtidy_df`:
  - The number of observations in the resulting dataset `Trashtidy_df` is **`r nrow(Trashtidy_df)`**. 
  - There are **`r ncol(Trashtidy_df)`** variables.
  - The key variables in this dataset are **dumpster**, **month**, **year**, **date** and etc. 
  - All the variables are **`r colnames(Trashtidy_df)`**. 
  - The total weight of trash collected by Professor Trash Wheel was **`r sum(filter(Trashtidy_df,type == "Professor Trash Wheel") |> pull(weight_tons))`** tons.
  - The total number of cigarette butts collected by Gwynnda in July of 2021 was **`r sum(filter(Trashtidy_df,type == "Gwynnda Trash Wheel", month == "July", year == "2021") |> pull(cigarette_butts))`**.
  
## Problem 3: 

- First we import, clean, and tidy the `MCI_baseline` dataset.

```{r}
bl_df =
  read_csv("./data/data_mci/MCI_baseline.csv", skip = 1, na = ".")|>
  janitor::clean_names() |>
  rename(study_id = id) |> 
  filter(current_age < age_at_onset | is.na(age_at_onset)) |> 
  mutate(
    sex = 
      case_match(
        sex, 
        1 ~ "male", 
        0 ~ "female"),
    apoe4 = 
      case_match(
        apoe4, 
        1 ~ "apoe4 carrier", 
        0 ~ "apoe4 non-carrier"),
    age_at_onset = as.double(age_at_onset))

bl_df
```

- Below are the important steps when I am cleaning the `MCI_baseline` dataset:
  - I used `read_csv` to read the baseline sas file. Within that, I used `skip = 1` to skip the first row because it is data-unrelated. 
  - I used `janitor::clean_names()` to clean the column names.
  - I used `rename(study_id = id)` to mactch the the name variable **id** to be the same as the one in later biomaker dataset.
  - I used `filter(current_age < age_at_onset | is.na(age_at_onset))` to keep the participants whoes current age is smaller than age of the onset, also keep the participants free of MCI at the age at onset.
  - I used `mutate(case_match)` to appropriately encoded variables **sex** and **apoe4**.
  
- Below are the relevant features of `bl_df` dataset:
  - There were **`r nrow(bl_df)`** participants recruited.
  - Of recruited people, there are **`r count(filter(bl_df, age_at_onset != "NA"))`** developed MCI.
  - The average baseline age is **`r mean(pull(bl_df, current_age))`**.
  - The proportion of women in the study are APOE4 carriers is **`r nrow(filter(bl_df, sex == "female", apoe4 == "apoe4 carrier"))/nrow(filter(bl_df, sex == "female"))`**.

- Next we import, clean, and tidy the `mci_amyloid` dataset.

```{r}
bio_df =
  read_csv("./data/data_mci/mci_amyloid.csv", skip = 1)|>
  janitor::clean_names() |>
  pivot_longer(
    baseline:time_8,
    names_to = "visit", 
    values_to = "time_elapsed",
    names_prefix = "time_") |> 
  mutate(
    visit = replace(visit, visit == "baseline", "0"))

bio_df
```

- Below are the important steps when I am cleaning the `mci_amyloid` dataset:
  - A lot of code are the similar when I cleaned the baseline dataset.
  - I used `pivot_longer()` to make this dataset from wider to longer, because the visits are spread across the column, which correponds to five times.
  - I used `names_prefix` to get rid of the prefix **time_**.
  - Also I used `mutate(visit = replace())` to change **baseline** to **0** to match other visit data.
  
- Below are the relevant features of `bio_df` dataset:
  - There are **`r nrow(bio_df)`** observations in `bio_df` dataset.
  - There are **`r ncol(bio_df)`** variables, which are **`r colnames(bio_df)`**.

- Next I wanna check whether some participants appear in only the baseline or amyloid datasets.

```{r}
baseline_unique_participants =
  bl_df |> 
  dplyr::anti_join(bio_df, by = "study_id")
```

- There are **`r nrow(baseline_unique_participants)`** participants appear in only the baseline datasets.

```{r}
biomarker_unique_participants =
  bio_df |> 
  dplyr::anti_join(bl_df, by = "study_id")
```

- There are **`r nrow(biomarker_unique_participants)`** observations appear in only the amyloid dataset. However, because every participants have five visit in cleaned and tidied amyloid dataset, we also can divide the observation by 5 to get **`r nrow(biomarker_unique_participants)/5`** participants only appear in the amyloid dataset.

- Finally I will combine the demographic and biomarker datasets

```{r}
comb_data = 
  inner_join(bio_df, bl_df, by = "study_id")

comb_data
```

- There are **`r nrow(comb_data)`** observations or **`r nrow(comb_data)/5`** participants appear in both the baseline and amyloid datasets. There are **`r ncol(comb_data)`** variables in these combined datasets, which are **`r colnames(comb_data)`**.

- However, like I said previously, there are 5 visit in tidy version of amyloid dataset. Therefore if we want to know how many people both in the tidied baseline and non-tidy amyloid datasets. We should do this.

```{r}
widebio_df =
  read_csv("./data/data_mci/mci_amyloid.csv", skip = 1)|>
  janitor::clean_names()

widebio_df
```

```{r}
comb_data2 = 
  inner_join(bl_df, widebio_df, by = "study_id")

comb_data2
```

- There are **`r nrow(comb_data2)`** participants appear in both the tidy-baseline and untidy-amyloid datasets. There are **`r ncol(comb_data2)`** variables in these combined datasets, which are **`r colnames(comb_data2)`**.


- Last but not the least, I will export the combined dataset.

```{r}
write_csv(comb_data,"data/comb_data.csv")
```

```{r}
write_csv(comb_data2,"data/comb_data2.csv")
```