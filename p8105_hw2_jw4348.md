p8105_hw2_jw4348
================
Jingyu Wang
2023-10-04

## Problem 1:

- First, we clean the data in `pols-month.csv.`.

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
    )
```

``` r
pols = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_num)`

- Then, we clean the data in `snp.csv`.

``` r
snp = 
  read_csv(
    "./data/fivethirtyeight_datasets/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
```

    ## Joining with `by = join_by(month_num)`

- Finally, we tidy the `unemployment` data so that it can be merged with
  the `pols` and `snp` datasets.

``` r
unemployment = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_abb)`

- Now we merge the three datasets!

``` r
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

``` r
str(data_538)
```

    ## tibble [822 × 13] (S3: tbl_df/tbl/data.frame)
    ##  $ year        : num [1:822] 1947 1947 1947 1947 1947 ...
    ##  $ month       : chr [1:822] "January" "February" "March" "April" ...
    ##  $ month_num   : int [1:822] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ gov_gop     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_gop     : num [1:822] 51 51 51 51 51 51 51 51 51 51 ...
    ##  $ rep_gop     : num [1:822] 253 253 253 253 253 253 253 253 253 253 ...
    ##  $ gov_dem     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_dem     : num [1:822] 45 45 45 45 45 45 45 45 45 45 ...
    ##  $ rep_dem     : num [1:822] 198 198 198 198 198 198 198 198 198 198 ...
    ##  $ president   : chr [1:822] "dem" "dem" "dem" "dem" ...
    ##  $ month_abb   : chr [1:822] "Jan" "Feb" "Mar" "Apr" ...
    ##  $ close       : num [1:822] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ unemployment: num [1:822] NA NA NA NA NA NA NA NA NA NA ...

- Let’s talk about the 538 datasets. The `pols` data has 822
  observations and 11 variables and tells us about the party affiliation
  distribution (democrat or republican) for governors and senators for a
  given year from years 1947 to 2015. It also tells us whether the
  sitting president was a democrat or republican. The `snp` data has 787
  observations and 3 variables, ranging from years 1950 to 2015. The
  `unemployment` data has 816 observations and 3 variables ranging from
  years 1948 to 2015. In Januarys in or after 1975 in which a democrat
  was president, the **average unemployment rate was 6.57**. The average
  unemployment rate over the same time period in which a republican was
  president was 6.47.

## Problem 2:

- First we read and clean the `Mr. Trash Wheel sheet`.

``` r
MrTrashWheel_df = 
  readxl::read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N586") |> 
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(
    homes_powered = (weight_tons * 500) / 30,
    type = "Mr Trash Wheel",
    year = as.double(year)
  )
 
MrTrashWheel_df
```

    ## # A tibble: 584 × 15
    ##    dumpster month  year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 574 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>, type <chr>

- Next we read and clean the `Professor Trash Wheel`.

``` r
ProfessorTrashWheel_df = 
  readxl::read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M108") |> 
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(
    homes_powered = (weight_tons * 500) / 30,
    type = "Professor Trash Wheel"
    )

ProfessorTrashWheel_df
```

    ## # A tibble: 106 × 14
    ##    dumpster month     year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 January   2017 2017-01-02 00:00:00        1.79                 15
    ##  2        2 January   2017 2017-01-30 00:00:00        1.58                 15
    ##  3        3 February  2017 2017-02-26 00:00:00        2.32                 18
    ##  4        4 February  2017 2017-02-26 00:00:00        3.72                 15
    ##  5        5 February  2017 2017-02-28 00:00:00        1.45                 15
    ##  6        6 March     2017 2017-03-30 00:00:00        1.71                 15
    ##  7        7 April     2017 2017-04-01 00:00:00        1.82                 15
    ##  8        8 April     2017 2017-04-20 00:00:00        2.37                 15
    ##  9        9 May       2017 2017-05-10 00:00:00        2.64                 15
    ## 10       10 May       2017 2017-05-26 00:00:00        2.78                 15
    ## # ℹ 96 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>, type <chr>

- Then we read and clean the `Gwynnda Trash Wheel`.

``` r
GwynndaTrashWheel_df = 
  readxl::read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet =   "Gwynnda Trash Wheel", range = "A2:L157") |> 
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(
    homes_powered = (weight_tons * 500) / 30,
    type = "Gwynnda Trash Wheel"
  )

GwynndaTrashWheel_df
```

    ## # A tibble: 155 × 13
    ##    dumpster month   year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>  <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 July    2021 2021-07-03 00:00:00        0.93                 15
    ##  2        2 July    2021 2021-07-07 00:00:00        2.26                 15
    ##  3        3 July    2021 2021-07-07 00:00:00        1.62                 15
    ##  4        4 July    2021 2021-07-16 00:00:00        1.76                 15
    ##  5        5 July    2021 2021-07-30 00:00:00        1.53                 15
    ##  6        6 August  2021 2021-08-11 00:00:00        2.06                 15
    ##  7        7 August  2021 2021-08-14 00:00:00        1.9                  15
    ##  8        8 August  2021 2021-08-16 00:00:00        2.16                 15
    ##  9        9 August  2021 2021-08-16 00:00:00        2.6                  15
    ## 10       10 August  2021 2021-08-17 00:00:00        3.21                 15
    ## # ℹ 145 more rows
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>, type <chr>

- Now we merge the three datasets, and proce a single tidy dataset named
  `Trashtidy_df`.

``` r
Trashtidy_df = 
  bind_rows(MrTrashWheel_df, ProfessorTrashWheel_df, GwynndaTrashWheel_df) |>
  janitor::clean_names() 

Trashtidy_df
```

    ## # A tibble: 845 × 15
    ##    dumpster month  year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 835 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>, type <chr>

- Blow is the description of dataset `Trashtidy_df`:
  - The number of observations in the resulting dataset `Trashtidy_df`
    is **845**.
  - There are **15** variables.
  - The key variables in this dataset are **dumpster**, **month**,
    **year**, **date** and etc.
  - All the variables are **dumpster, month, year, date, weight_tons,
    volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
    glass_bottles, plastic_bags, wrappers, sports_balls, homes_powered,
    type**.
  - The total weight of trash collected by Professor Trash Wheel was
    **216.26** tons.
  - The total number of cigarette butts collected by Gwynnda in July of
    2021 was **1.63^{4}**.

## Problem 3:

- First we import, clean, and tidy the `MCI_baseline` dataset.

``` r
bl_df =
  read_csv("./data/data_mci/MCI_baseline.csv", skip = 1, na = ".")|>
  janitor::clean_names() |>
  rename(study_id = id) |> 
  filter(current_age < age_at_onset | is.na(age_at_onset)) |> 
  mutate(
    sex = 
      case_match(
        sex, 
        1 ~ "male", 
        0 ~ "female"),
    apoe4 = 
      case_match(
        apoe4, 
        1 ~ "apoe4 carrier", 
        0 ~ "apoe4 non-carrier"),
    age_at_onset = as.double(age_at_onset))
```

    ## Rows: 483 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (6): ID, Current Age, Sex, Education, apoe4, Age at onset
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bl_df
```

    ## # A tibble: 479 × 6
    ##    study_id current_age sex    education apoe4             age_at_onset
    ##       <dbl>       <dbl> <chr>      <dbl> <chr>                    <dbl>
    ##  1        1        63.1 female        16 apoe4 carrier             NA  
    ##  2        2        65.6 female        20 apoe4 carrier             NA  
    ##  3        3        62.5 male          16 apoe4 carrier             66.8
    ##  4        4        69.8 female        16 apoe4 non-carrier         NA  
    ##  5        5        66   male          16 apoe4 non-carrier         68.7
    ##  6        6        62.5 male          16 apoe4 non-carrier         NA  
    ##  7        7        66.5 male          18 apoe4 non-carrier         74  
    ##  8        8        67.2 female        18 apoe4 non-carrier         NA  
    ##  9        9        66.7 female        16 apoe4 non-carrier         NA  
    ## 10       10        64.1 female        18 apoe4 non-carrier         NA  
    ## # ℹ 469 more rows

- Below are the important steps when I am cleaning the `MCI_baseline`
  dataset:
  - I used `read_csv` to read the baseline sas file. Within that, I used
    `skip = 1` to skip the first row because it is data-unrelated.
  - I used `janitor::clean_names()` to clean the column names.
  - I used `rename(study_id = id)` to mactch the the name variable
    **id** to be the same as the one in later biomaker dataset.
  - I used `filter(current_age < age_at_onset | is.na(age_at_onset))` to
    keep the participants whoes current age is smaller than age of the
    onset, also keep the participants free of MCI at the age at onset.
  - I used `mutate(case_match)` to appropriately encoded variables
    **sex** and **apoe4**.
- Below are the relevant features of `bl_df` dataset:
  - There were **479** participants recruited.
  - Of recruited people, there are **93** developed MCI.
  - The average baseline age is **65.0286013**.
  - The proportion of women in the study are APOE4 carriers is **0.3**.
- Next we import, clean, and tidy the `mci_amyloid` dataset.

``` r
bio_df =
  read_csv("./data/data_mci/mci_amyloid.csv", skip = 1)|>
  janitor::clean_names() |>
  pivot_longer(
    baseline:time_8,
    names_to = "visit", 
    values_to = "time_elapsed",
    names_prefix = "time_") |> 
  mutate(
    visit = replace(visit, visit == "baseline", "0"))
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bio_df
```

    ## # A tibble: 2,435 × 3
    ##    study_id visit time_elapsed
    ##       <dbl> <chr> <chr>       
    ##  1        1 0     0.1105487   
    ##  2        1 2     <NA>        
    ##  3        1 4     0.109325197 
    ##  4        1 6     0.104756131 
    ##  5        1 8     0.107257697 
    ##  6        2 0     0.107481183 
    ##  7        2 2     0.109157373 
    ##  8        2 4     0.109457839 
    ##  9        2 6     0.105729713 
    ## 10        2 8     0.10661845  
    ## # ℹ 2,425 more rows

- Below are the important steps when I am cleaning the `mci_amyloid`
  dataset:
  - A lot of code are the similar when I cleaned the baseline dataset.
  - I used `pivot_longer()` to make this dataset from wider to longer,
    because the visits are spread across the column, which correponds to
    five times.
  - I used `names_prefix` to get rid of the prefix **time\_**.
  - Also I used `mutate(visit = replace())` to change **baseline** to
    **0** to match other visit data.
- Below are the relevant features of `bio_df` dataset:
  - There are **2435** observations in `bio_df` dataset.
  - There are **3** variables, which are **study_id, visit,
    time_elapsed**.
- Next I wanna check whether some participants appear in only the
  baseline or amyloid datasets.

``` r
baseline_unique_participants =
  bl_df |> 
  dplyr::anti_join(bio_df, by = "study_id")
```

- There are **8** participants appear in only the baseline datasets.

``` r
biomarker_unique_participants =
  bio_df |> 
  dplyr::anti_join(bl_df, by = "study_id")
```

- There are **80** observations appear in only the amyloid dataset.
  However, because every participants have five visit in cleaned and
  tidied amyloid dataset, we also can divide the observation by 5 to get
  **16** participants only appear in the amyloid dataset.

- Finally I will combine the demographic and biomarker datasets

``` r
comb_data = 
  inner_join(bio_df, bl_df, by = "study_id")

comb_data
```

    ## # A tibble: 2,355 × 8
    ##    study_id visit time_elapsed current_age sex    education apoe4   age_at_onset
    ##       <dbl> <chr> <chr>              <dbl> <chr>      <dbl> <chr>          <dbl>
    ##  1        1 0     0.1105487           63.1 female        16 apoe4 …           NA
    ##  2        1 2     <NA>                63.1 female        16 apoe4 …           NA
    ##  3        1 4     0.109325197         63.1 female        16 apoe4 …           NA
    ##  4        1 6     0.104756131         63.1 female        16 apoe4 …           NA
    ##  5        1 8     0.107257697         63.1 female        16 apoe4 …           NA
    ##  6        2 0     0.107481183         65.6 female        20 apoe4 …           NA
    ##  7        2 2     0.109157373         65.6 female        20 apoe4 …           NA
    ##  8        2 4     0.109457839         65.6 female        20 apoe4 …           NA
    ##  9        2 6     0.105729713         65.6 female        20 apoe4 …           NA
    ## 10        2 8     0.10661845          65.6 female        20 apoe4 …           NA
    ## # ℹ 2,345 more rows

- There are **2355** observations or **471** participants appear in both
  the baseline and amyloid datasets. There are **8** variables in these
  combined datasets, which are **study_id, visit, time_elapsed,
  current_age, sex, education, apoe4, age_at_onset**.

- However, like I said previously, there are 5 visit in tidy version of
  amyloid dataset. Therefore if we want to know how many people both in
  the tidied baseline and non-tidy amyloid datasets. We should do this.

``` r
widebio_df =
  read_csv("./data/data_mci/mci_amyloid.csv", skip = 1)|>
  janitor::clean_names()
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
widebio_df
```

    ## # A tibble: 487 × 6
    ##    study_id baseline    time_2      time_4      time_6      time_8     
    ##       <dbl> <chr>       <chr>       <chr>       <chr>       <chr>      
    ##  1        1 0.1105487   <NA>        0.109325197 0.104756131 0.107257697
    ##  2        2 0.107481183 0.109157373 0.109457839 0.105729713 0.10661845 
    ##  3        3 0.106087034 0.108744509 0.106065035 <NA>        0.106152357
    ##  4        4 0.109251358 0.108699686 0.110540386 0.107476797 0.111212209
    ##  5        5 0.107950408 0.112273883 0.115139677 0.106606054 0.106052066
    ##  6        6 0.112426974 0.112853415 0.11143945  0.110279277 0.114982747
    ##  7        7 0.112246391 <NA>        0.104251905 0.112485583 0.112055612
    ##  8        8 0.109563372 0.109470828 <NA>        0.108742168 0.110268552
    ##  9        9 0.112101884 0.109781199 0.108832888 <NA>        <NA>       
    ## 10       10 0.1116094   0.111592149 <NA>        <NA>        0.110051296
    ## # ℹ 477 more rows

``` r
comb_data2 = 
  inner_join(bl_df, widebio_df, by = "study_id")

comb_data2
```

    ## # A tibble: 471 × 11
    ##    study_id current_age sex    education apoe4      age_at_onset baseline time_2
    ##       <dbl>       <dbl> <chr>      <dbl> <chr>             <dbl> <chr>    <chr> 
    ##  1        1        63.1 female        16 apoe4 car…         NA   0.11054… <NA>  
    ##  2        2        65.6 female        20 apoe4 car…         NA   0.10748… 0.109…
    ##  3        3        62.5 male          16 apoe4 car…         66.8 0.10608… 0.108…
    ##  4        4        69.8 female        16 apoe4 non…         NA   0.10925… 0.108…
    ##  5        5        66   male          16 apoe4 non…         68.7 0.10795… 0.112…
    ##  6        6        62.5 male          16 apoe4 non…         NA   0.11242… 0.112…
    ##  7        7        66.5 male          18 apoe4 non…         74   0.11224… <NA>  
    ##  8        8        67.2 female        18 apoe4 non…         NA   0.10956… 0.109…
    ##  9        9        66.7 female        16 apoe4 non…         NA   0.11210… 0.109…
    ## 10       10        64.1 female        18 apoe4 non…         NA   0.11160… 0.111…
    ## # ℹ 461 more rows
    ## # ℹ 3 more variables: time_4 <chr>, time_6 <chr>, time_8 <chr>

- There are **471** participants appear in both the tidy-baseline and
  untidy-amyloid datasets. There are **11** variables in these combined
  datasets, which are **study_id, current_age, sex, education, apoe4,
  age_at_onset, baseline, time_2, time_4, time_6, time_8**.

- Last but not the least, I will export the combined dataset.

``` r
write_csv(comb_data,"data/comb_data.csv")
```

``` r
write_csv(comb_data2,"data/comb_data2.csv")
```
